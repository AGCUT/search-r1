# âœ… BLEU å’Œ ROUGE è¯„ä¼°æŒ‡æ ‡å·²å®ç°ï¼

## ğŸ‰ æ–°å¢åŠŸèƒ½

ç°åœ¨ Search-R1 æ”¯æŒä½¿ç”¨ **BLEU** å’Œ **ROUGE** è¯„ä¼°æŒ‡æ ‡è¿›è¡Œæ¨¡å‹è¯„ä¼°å’Œè®­ç»ƒï¼

### æ”¯æŒçš„æŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ | åˆ†æ•°èŒƒå›´ | é€‚ç”¨åœºæ™¯ | å®ç°æ–¹å¼ |
|------|------|---------|---------|---------|
| **bleu** | N-gram precision | 0.0 - 1.0 | é•¿æ–‡æœ¬ç”Ÿæˆ/ç¿»è¯‘ | âœ… çº¯Pythonå®ç° |
| **rouge_l** | Longest Common Subsequence | 0.0 - 1.0 | æ‘˜è¦/é•¿ç­”æ¡ˆ | âœ… çº¯Pythonå®ç° |
| **rouge_1** | Unigram overlap | 0.0 - 1.0 | é€šç”¨æ–‡æœ¬è¯„ä¼° | âœ… çº¯Pythonå®ç° |
| **rouge_2** | Bigram overlap | 0.0 - 1.0 | æ›´ä¸¥æ ¼çš„è¯„ä¼° | âœ… çº¯Pythonå®ç° |

**æ— éœ€é¢å¤–ä¾èµ–ï¼** æ‰€æœ‰æŒ‡æ ‡éƒ½æ˜¯çº¯Pythonå®ç°,ä¸éœ€è¦å®‰è£…ä»»ä½•å¤–éƒ¨åº“ã€‚

---

## ğŸš€ å¿«é€Ÿä½¿ç”¨

### 1. ä½¿ç”¨ ROUGE-L è¯„ä¼° (æ¨è)

```bash
# å¯åŠ¨æ£€ç´¢æœåŠ¡å™¨
bash retrieval_launch.sh

# ä¿®æ”¹è¯„ä¼°è„šæœ¬
vim configs/qrecc/compare_base_vs_trained_f1.sh

# è®¾ç½®è¯„ä¼°æŒ‡æ ‡ä¸º rouge_l
export REWARD_FN='rouge_l'

# è¿è¡Œè¯„ä¼°
bash configs/qrecc/compare_base_vs_trained_f1.sh
```

### 2. ä½¿ç”¨ BLEU è¯„ä¼°

```bash
# è®¾ç½®è¯„ä¼°æŒ‡æ ‡ä¸º bleu
export REWARD_FN='bleu'

bash configs/qrecc/compare_base_vs_trained_f1.sh
```

### 3. ä½¿ç”¨ ROUGE-1 æˆ– ROUGE-2

```bash
# ROUGE-1 (unigram)
export REWARD_FN='rouge_1'

# ROUGE-2 (bigram)
export REWARD_FN='rouge_2'

bash configs/qrecc/compare_base_vs_trained_f1.sh
```

---

## ğŸ“Š æŒ‡æ ‡å¯¹æ¯”

### QReCC æ•°æ®é›†æ¨èä½¿ç”¨

ç”±äº QReCC ç­”æ¡ˆæ™®éè¾ƒé•¿(å¹³å‡ 10-30 ä¸ªå•è¯),æ¨èä½¿ç”¨:

1. **ROUGE-L** (é¦–é€‰) - è€ƒè™‘æœ€é•¿å…¬å…±å­åºåˆ—,é€‚åˆé•¿ç­”æ¡ˆ
2. **F1** - Tokençº§åˆ«é‡å ,å¹³è¡¡precisionå’Œrecall
3. **ROUGE-1** - Unigramé‡å ,å®½æ¾è¯„ä¼°
4. **BLEU** - N-gram precision,é€‚åˆç”Ÿæˆè´¨é‡è¯„ä¼°

### å„æŒ‡æ ‡ç‰¹ç‚¹

#### BLEU
- **ä¼˜ç‚¹**:
  - è€ƒè™‘å¤šä¸ªn-gramçº§åˆ« (1-4gram)
  - æœ‰brevity penalty,æƒ©ç½šè¿‡çŸ­çš„è¾“å‡º
  - å¹¿æ³›ç”¨äºæœºå™¨ç¿»è¯‘è¯„ä¼°
- **ç¼ºç‚¹**:
  - åªçœ‹precision,ä¸çœ‹recall
  - å¯¹äºçŸ­æ–‡æœ¬å¯èƒ½è¿‡äºä¸¥æ ¼
- **é€‚ç”¨**: é•¿æ–‡æœ¬ç”Ÿæˆ,ç¿»è¯‘ä»»åŠ¡

#### ROUGE-L
- **ä¼˜ç‚¹**:
  - åŸºäºæœ€é•¿å…¬å…±å­åºåˆ—(LCS)
  - è€ƒè™‘å¥å­ç»“æ„ç›¸ä¼¼æ€§
  - F1-based,å¹³è¡¡precisionå’Œrecall
- **ç¼ºç‚¹**:
  - è®¡ç®—ç›¸å¯¹å¤æ‚
  - å¯¹å•è¯é¡ºåºæ•æ„Ÿ
- **é€‚ç”¨**: æ‘˜è¦,é•¿ç­”æ¡ˆQA **(æ¨èç”¨äºQReCC)**

#### ROUGE-1
- **ä¼˜ç‚¹**:
  - Unigramçº§åˆ«,æœ€å®½æ¾
  - è®¡ç®—ç®€å•,é€Ÿåº¦å¿«
  - å®¹å¿é¡ºåºå·®å¼‚
- **ç¼ºç‚¹**:
  - ä¸è€ƒè™‘é¡ºåºä¿¡æ¯
  - å¯èƒ½ç»™éšæœºè¯æ±‡å †ç Œé«˜åˆ†
- **é€‚ç”¨**: å¿«é€Ÿè¯„ä¼°,å®½æ¾åŒ¹é…

#### ROUGE-2
- **ä¼˜ç‚¹**:
  - Bigramçº§åˆ«,è€ƒè™‘éƒ¨åˆ†é¡ºåº
  - æ¯”ROUGE-1æ›´ä¸¥æ ¼
  - è®¡ç®—ä»ç„¶è¾ƒå¿«
- **ç¼ºç‚¹**:
  - å¯¹çŸ­æ–‡æœ¬ä¸å¤ªé€‚ç”¨
  - å¯èƒ½è¿‡äºä¸¥æ ¼
- **é€‚ç”¨**: ä¸­é•¿æ–‡æœ¬,éœ€è¦éƒ¨åˆ†é¡ºåºä¿¡æ¯

---

## ğŸ“ˆ åˆ†æ•°è§£è¯»

### BLEU Score

| åˆ†æ•°èŒƒå›´ | è´¨é‡ | è¯´æ˜ |
|---------|------|------|
| 0.0 - 0.1 | å·® | å‡ ä¹æ²¡æœ‰overlap |
| 0.1 - 0.2 | å¯ç†è§£ | æœ‰ä¸€å®šoverlap |
| 0.2 - 0.3 | å¯æ¥å— | ä¸­ç­‰è´¨é‡ |
| 0.3 - 0.4 | å¥½ | è¾ƒé«˜è´¨é‡ |
| 0.4+ | å¾ˆå¥½ | é«˜è´¨é‡ |

**æ³¨æ„**: BLEUåˆ†æ•°é€šå¸¸è¾ƒä½,0.3+å°±å·²ç»å¾ˆå¥½äº†ï¼

### ROUGE Scores

| åˆ†æ•°èŒƒå›´ | è´¨é‡ | è¯´æ˜ |
|---------|------|------|
| 0.0 - 0.2 | å·® | å¾ˆå°‘overlap |
| 0.2 - 0.4 | ä¸€èˆ¬ | æœ‰ä¸€å®šç›¸ä¼¼æ€§ |
| 0.4 - 0.6 | å¥½ | è¾ƒé«˜ç›¸ä¼¼æ€§ |
| 0.6 - 0.8 | å¾ˆå¥½ | é«˜åº¦ç›¸ä¼¼ |
| 0.8+ | æå¥½ | å‡ ä¹å®Œå…¨åŒ¹é… |

**æ³¨æ„**: ROUGEåˆ†æ•°é€šå¸¸æ¯”BLEUé«˜,0.5+å°±æ˜¯ä¸é”™çš„ç»“æœã€‚

---

## ğŸ”§ é«˜çº§ç”¨æ³•

### 1. åœ¨è®­ç»ƒä¸­ä½¿ç”¨ ROUGE-L

```bash
vim configs/qrecc/train_qrecc_ppo_plan_b.sh

# æ·»åŠ reward functionå‚æ•°:
+algorithm.reward_fn=rouge_l

# è¿è¡Œè®­ç»ƒ
bash configs/qrecc/train_qrecc_ppo_plan_b.sh
```

### 2. è¯„ä¼°è„šæœ¬æ¨¡æ¿

åˆ›å»ºè‡ªå®šä¹‰è¯„ä¼°è„šæœ¬:

```bash
#!/bin/bash
export CUDA_VISIBLE_DEVICES=0,1,2,3
export CHECKPOINT_PATH="your/checkpoint/path"
export REWARD_FN='rouge_l'  # æˆ– bleu, rouge_1, rouge_2
export DATA_DIR='data/qrecc_raw'

python3 -m verl.trainer.main_ppo \
    data.val_files=$DATA_DIR/qrecc_test.json \
    +algorithm.reward_fn=$REWARD_FN \
    actor_rollout_ref.model.path=$CHECKPOINT_PATH \
    +trainer.val_only=true \
    ... # å…¶ä»–å‚æ•°
```

### 3. ç»„åˆå¤šä¸ªæŒ‡æ ‡è¯„ä¼°

ä½ å¯ä»¥è¿è¡Œå¤šæ¬¡è¯„ä¼°,æ¯æ¬¡ä½¿ç”¨ä¸åŒæŒ‡æ ‡:

```bash
for METRIC in rouge_l rouge_1 bleu f1; do
    echo "Evaluating with $METRIC..."
    export REWARD_FN=$METRIC
    bash configs/qrecc/evaluate_qrecc_with_f1.sh > results/eval_$METRIC.log
done

# å¯¹æ¯”æ‰€æœ‰ç»“æœ
grep "average_score" results/eval_*.log
```

---

## ğŸ“ ä»£ç ç¤ºä¾‹

### Pythonä¸­ç›´æ¥ä½¿ç”¨

```python
from verl.utils.reward_score import qrecc_bleu_rouge

# é¢„æµ‹ç­”æ¡ˆ
prediction = "The capital of France is Paris, which is located in the northern part of the country."

# çœŸå®ç­”æ¡ˆ
references = [
    "Paris is the capital of France.",
    "The capital of France is Paris."
]

# è®¡ç®—BLEU
bleu_score = qrecc_bleu_rouge.bleu_check(prediction, references)
print(f"BLEU: {bleu_score:.4f}")

# è®¡ç®—ROUGE-L
rouge_l_score = qrecc_bleu_rouge.rouge_l_check(prediction, references)
print(f"ROUGE-L: {rouge_l_score:.4f}")

# è®¡ç®—ROUGE-1
rouge_1_score = qrecc_bleu_rouge.rouge_1_check(prediction, references)
print(f"ROUGE-1: {rouge_1_score:.4f}")

# è®¡ç®—ROUGE-2
rouge_2_score = qrecc_bleu_rouge.rouge_2_check(prediction, references)
print(f"ROUGE-2: {rouge_2_score:.4f}")
```

### åœ¨veRLæ¡†æ¶ä¸­ä½¿ç”¨

```python
# veRLæ¡†æ¶ä¼šè‡ªåŠ¨è°ƒç”¨,åªéœ€é…ç½®å³å¯
# åœ¨ main_ppo.py ä¸­å·²ç»é›†æˆ
```

---

## ğŸ†š ä¸ç°æœ‰æŒ‡æ ‡å¯¹æ¯”

| æŒ‡æ ‡ | ç±»å‹ | åˆ†æ•°èŒƒå›´ | é€‚åˆé•¿ç­”æ¡ˆ | éœ€è¦å¤–éƒ¨åº“ | é€Ÿåº¦ |
|------|------|---------|-----------|-----------|------|
| **EM** | Binary | 0 or 1 | âŒ å¦ | âŒ ä¸éœ€è¦ | âš¡âš¡âš¡ æœ€å¿« |
| **F1** | Continuous | 0.0 - 1.0 | âœ… æ˜¯ | âŒ ä¸éœ€è¦ | âš¡âš¡ å¿« |
| **BLEU** | Continuous | 0.0 - 1.0 | âœ… æ˜¯ | âŒ ä¸éœ€è¦ | âš¡âš¡ å¿« |
| **ROUGE-L** | Continuous | 0.0 - 1.0 | âœ… æ˜¯ | âŒ ä¸éœ€è¦ | âš¡ ä¸­ç­‰ |
| **ROUGE-1** | Continuous | 0.0 - 1.0 | âœ… æ˜¯ | âŒ ä¸éœ€è¦ | âš¡âš¡ å¿« |
| **ROUGE-2** | Continuous | 0.0 - 1.0 | âœ… æ˜¯ | âŒ ä¸éœ€è¦ | âš¡âš¡ å¿« |
| **BERTScore** | Continuous | 0.0 - 1.0 | âœ… æ˜¯ | âœ… éœ€è¦ | ğŸ¢ æ…¢ |

---

## ğŸ’¡ å®é™…ä½¿ç”¨å»ºè®®

### å¯¹äº QReCC è¯„ä¼°

**æ¨èæŒ‡æ ‡ç»„åˆ**:
1. **ä¸»æŒ‡æ ‡**: `rouge_l` (æœ€é€‚åˆé•¿ç­”æ¡ˆ)
2. **è¾…åŠ©æŒ‡æ ‡**: `f1` (tokençº§åˆ«éªŒè¯)
3. **å‚è€ƒæŒ‡æ ‡**: `rouge_1` (å®½æ¾åŒ¹é…)

**è¯„ä¼°æµç¨‹**:
```bash
# 1. ä½¿ç”¨ ROUGE-L ä¸»è¯„ä¼°
export REWARD_FN='rouge_l'
bash configs/qrecc/compare_base_vs_trained_f1.sh

# 2. ä½¿ç”¨ F1 è¾…åŠ©éªŒè¯
export REWARD_FN='f1'
bash configs/qrecc/compare_base_vs_trained_f1.sh

# 3. å¯¹æ¯”ç»“æœ
```

### å¯¹äºè®­ç»ƒ

**æ¨è**:
- **åˆæœŸè®­ç»ƒ**: ä½¿ç”¨ `f1` (ç®€å•æœ‰æ•ˆ)
- **ä¸­æœŸè°ƒä¼˜**: åˆ‡æ¢åˆ° `rouge_l` (æ›´å‡†ç¡®)
- **æœ€ç»ˆå¾®è°ƒ**: æ ¹æ®å…·ä½“ä»»åŠ¡é€‰æ‹©

---

## ğŸ“‚ æ–°å¢æ–‡ä»¶

1. **`verl/utils/reward_score/qrecc_bleu_rouge.py`** â­
   - BLEU å®ç°
   - ROUGE-L å®ç°
   - ROUGE-1 å®ç°
   - ROUGE-2 å®ç°
   - ä¸veRLæ¡†æ¶é›†æˆçš„scoringå‡½æ•°

2. **`verl/trainer/main_ppo.py`** (å·²æ›´æ–°)
   - æ·»åŠ äº† BLEU/ROUGE æ”¯æŒ
   - æ›´æ–°äº† `_select_rm_score_fn` å‡½æ•°
   - æ›´æ–°äº† RewardManager æ–‡æ¡£

3. **`docs/qrecc_bleu_rouge_guide.md`** (æœ¬æ–‡æ¡£)
   - ä½¿ç”¨æŒ‡å—

---

## ğŸ¯ æ€»ç»“

**âœ… å·²å®ç°åŠŸèƒ½:**
- BLEU score (n-gram precision)
- ROUGE-L (LCS-based)
- ROUGE-1 (unigram)
- ROUGE-2 (bigram)
- å®Œæ•´çš„veRLæ¡†æ¶é›†æˆ
- çº¯Pythonå®ç°,æ— éœ€é¢å¤–ä¾èµ–

**ğŸ“ ä½¿ç”¨æ–¹æ³•:**
```bash
# åªéœ€è®¾ç½®ä¸€ä¸ªç¯å¢ƒå˜é‡!
export REWARD_FN='rouge_l'  # æˆ– bleu, rouge_1, rouge_2

# ç„¶åè¿è¡Œè¯„ä¼°
bash configs/qrecc/compare_base_vs_trained_f1.sh
```

**ğŸš€ ç°åœ¨ä½ å¯ä»¥:**
1. ä½¿ç”¨ ROUGE-L è¯„ä¼° QReCC é•¿ç­”æ¡ˆ
2. ä½¿ç”¨ BLEU è¯„ä¼°æ–‡æœ¬ç”Ÿæˆè´¨é‡
3. ä½¿ç”¨ ROUGE-1/2 è¿›è¡Œå¤šå±‚æ¬¡è¯„ä¼°
4. åœ¨è®­ç»ƒä¸­ä½¿ç”¨è¿™äº›æŒ‡æ ‡ä½œä¸ºreward

---

éœ€è¦å¸®åŠ©? æŸ¥çœ‹å…¶ä»–æ–‡æ¡£:
- veRL æ¡†æ¶è¯„ä¼°: `docs/qrecc_verl_f1_evaluation.md`
- F1/BERTScore è¯„ä¼°: `docs/qrecc_bertscore_f1_quickstart.md`
- å®Œæ•´è¯„ä¼°æŒ‡å—: `docs/qrecc_evaluation_guide.md`