# QReCCæ•°æ®é›†å®æ–½è®¡åˆ’

## ğŸ“‹ é¡¹ç›®æ¦‚è§ˆ

### é¡¹ç›®ç›®æ ‡
å°†Search-R1ä»**å•è½®é—®ç­”**æ‰©å±•åˆ°**å¯¹è¯å¼æ£€ç´¢é—®ç­”**ï¼Œè®©æ¨¡å‹å­¦ä¼šï¼š
1. ç†è§£å¯¹è¯ä¸Šä¸‹æ–‡
2. æ ¹æ®å¯¹è¯å†å²æ”¹å†™æ£€ç´¢query
3. åœ¨å¤šè½®å¯¹è¯ä¸­è¿›è¡Œæ¨ç†å’Œæœç´¢

### æ ¸å¿ƒåˆ›æ–°ç‚¹
- **å¯¹è¯ä¸Šä¸‹æ–‡å»ºæ¨¡**ï¼šä¸æ˜¯ç‹¬ç«‹å›ç­”é—®é¢˜ï¼Œè€Œæ˜¯ç†è§£ä¹‹å‰çš„é—®ç­”å†å²
- **Queryæ”¹å†™èƒ½åŠ›**ï¼šå°†çœç•¥çš„æŒ‡ä»£è¯è¡¥å…¨ï¼ˆå¦‚"ä»–æ˜¯è°" â†’ "Barack Obamaæ˜¯è°"ï¼‰
- **æ¸è¿›å¼ä¿¡æ¯æ”¶é›†**ï¼šé€šè¿‡å¤šè½®å¯¹è¯é€æ­¥æ”¶é›†ä¿¡æ¯

---

## ğŸ“Š é˜¶æ®µä¸€ï¼šæ•°æ®é›†ç†è§£ä¸åˆ†æ

### 1.1 ä¸‹è½½å¹¶æ¢ç´¢QReCCæ•°æ®é›†
**ä»»åŠ¡æ¸…å•ï¼š**
- ä»HuggingFaceä¸‹è½½QReCCæ•°æ®é›†
- ç†è§£æ•°æ®é›†ç»“æ„å’Œå­—æ®µå«ä¹‰
- ç»Ÿè®¡æ•°æ®é›†è§„æ¨¡å’Œç‰¹å¾
- åˆ†æå¯¹è¯é•¿åº¦åˆ†å¸ƒ
- æŸ¥çœ‹å‡ ä¸ªå…¸å‹æ ·æœ¬

**å…³é”®å­—æ®µåˆ†æï¼š**
- `Conversation_no`: å¯¹è¯ID
- `Turn_no`: å¯¹è¯è½®æ¬¡
- `Question`: å½“å‰é—®é¢˜ï¼ˆå¯èƒ½æœ‰çœç•¥/æŒ‡ä»£ï¼‰
- `Answer`: æ ‡å‡†ç­”æ¡ˆ
- `Conversation_context`: å¯¹è¯å†å²
- `Rewrite`: æ”¹å†™åçš„ç‹¬ç«‹é—®é¢˜ï¼ˆé‡è¦ï¼ï¼‰
- `Conversation_source`: æ•°æ®æ¥æº

**ä»£ç ç¤ºä¾‹ï¼š**
```python
# ä¸‹è½½æ•°æ®é›†
datasets.load_dataset('McGill-NLP/QReCC')

# æ¢ç´¢æ•°æ®
from datasets import load_dataset
dataset = load_dataset('McGill-NLP/QReCC')
print(dataset)
print(dataset['train'][0])  # æŸ¥çœ‹ç¬¬ä¸€ä¸ªæ ·æœ¬
```

### 1.2 å¯¹æ¯”Search-R1åŸå§‹æ•°æ®æ ¼å¼
**åˆ†æå·®å¼‚ï¼š**
- åŸSearch-R1: å•è½®ç‹¬ç«‹é—®ç­”
- QReCC: å¤šè½®å¯¹è¯ï¼Œéœ€è¦ä¸Šä¸‹æ–‡

**éœ€è¦è§£å†³çš„é—®é¢˜ï¼š**
- å¦‚ä½•è¡¨ç¤ºå¯¹è¯å†å²ï¼Ÿ
- æ˜¯å¦ä½¿ç”¨æ”¹å†™åçš„queryï¼Ÿ
- å¦‚ä½•è®¾è®¡promptæ¨¡æ¿ï¼Ÿ

### 1.3 ç¡®å®šæŠ€æœ¯è·¯çº¿
**ä¸¤ç§å¯èƒ½çš„æ–¹æ¡ˆï¼š**

**æ–¹æ¡ˆAï¼šç«¯åˆ°ç«¯å¯¹è¯ï¼ˆæ¨èï¼‰**
- è¾“å…¥ï¼šå®Œæ•´å¯¹è¯å†å² + å½“å‰é—®é¢˜
- æ¨¡å‹è‡ªå·±å­¦ä¹ æ”¹å†™query
- æ›´æ¥è¿‘çœŸå®åº”ç”¨åœºæ™¯

**æ–¹æ¡ˆBï¼šä½¿ç”¨ground-truthæ”¹å†™**
- è¾“å…¥ï¼šæ”¹å†™åçš„ç‹¬ç«‹é—®é¢˜
- é™ä½éš¾åº¦ï¼Œå…ˆéªŒè¯å¯è¡Œæ€§
- å¯ä½œä¸ºbaseline

**å»ºè®®ï¼š** å…ˆå®ç°æ–¹æ¡ˆBéªŒè¯æµç¨‹ï¼Œå†å®ç°æ–¹æ¡ˆAè¿½æ±‚æ€§èƒ½

---

## ğŸ“ é˜¶æ®µäºŒï¼šæ•°æ®å¤„ç†è®¾è®¡

### 2.1 è®¾è®¡æ•°æ®Schema
**ç¡®å®šæ•°æ®ç»“æ„ï¼š**
```python
data = {
    "data_source": "qrecc",
    "prompt": [{
        "role": "user",
        "content": prompt_text,  # åŒ…å«å¯¹è¯å†å²
    }],
    "ability": "conversational-reasoning",
    "reward_model": {
        "style": "rule",
        "ground_truth": {"target": [answer]}
    },
    "extra_info": {
        'conversation_id': conv_id,
        'turn_no': turn_no,
        'rewrite': rewrite_query,
        'index': idx,
    }
}
```

### 2.2 è®¾è®¡Promptæ¨¡æ¿
**æ ¸å¿ƒæŒ‘æˆ˜ï¼šå¦‚ä½•è¡¨ç¤ºå¯¹è¯å†å²**

**æ–¹æ¡ˆBçš„æ¨¡æ¿ï¼ˆä½¿ç”¨æ”¹å†™åçš„queryï¼‰ï¼š**
```
Answer the given question.
You must conduct reasoning inside <think> and </think> first every time you get new information.
After reasoning, if you find you lack some knowledge, you can call a search engine by <search> query </search> and it will return the top searched results between <information> and </information>.
You can search as many times as your want.
If you find no further external knowledge needed, you can directly provide the answer inside <answer> and </answer>, without detailed illustrations.

Question: {rewrite_query}
```

**æ–¹æ¡ˆAçš„æ¨¡æ¿ï¼ˆç«¯åˆ°ç«¯å¯¹è¯ï¼‰ï¼š**
```
Answer the given question based on the conversation history.
You must conduct reasoning inside <think> and </think> first every time you get new information.
After reasoning, if you find you lack some knowledge, you can call a search engine by <search> query </search> and it will return the top searched results between <information> and </information>.
You can search as many times as your want.
If you find no further external knowledge needed, you can directly provide the answer inside <answer> and </answer>, without detailed illustrations.

Conversation History:
{format_conversation_history}

Current Question: {current_question}
```

**å¯¹è¯å†å²æ ¼å¼ç¤ºä¾‹ï¼š**
```
Turn 1:
Q: Who is the president of USA?
A: Joe Biden

Turn 2:
Q: How old is he?
```

### 2.3 æ•°æ®é¢„å¤„ç†ç­–ç•¥
**å¤„ç†æµç¨‹ï¼š**
1. æŒ‰ `Conversation_no` åˆ†ç»„
2. ä¸ºæ¯ä¸ªturnæ„å»ºä¸Šä¸‹æ–‡ï¼ˆåŒ…å«ä¹‹å‰çš„æ‰€æœ‰è½®æ¬¡ï¼‰
3. ç”Ÿæˆè®­ç»ƒæ ·æœ¬
4. å¤„ç†ç‰¹æ®Šæƒ…å†µï¼ˆç¬¬ä¸€è½®ã€è¶…é•¿å¯¹è¯ç­‰ï¼‰

**å…³é”®è€ƒè™‘ï¼š**
- å¯¹è¯å†å²çš„é•¿åº¦é™åˆ¶ï¼ˆtokenæ•°ï¼‰
  - å»ºè®®ï¼šä¿ç•™æœ€è¿‘3-5è½®
  - æˆ–ä½¿ç”¨æ»‘åŠ¨çª—å£
- å†å²è½®æ¬¡çš„è¡¨ç¤ºæ ¼å¼
  - æ¸…æ™°çš„Turnæ ‡è®°
- æ˜¯å¦åŒ…å«å†å²æœç´¢ç»“æœ
  - åˆæœŸå¯ä»¥ä¸åŒ…å«ï¼Œç®€åŒ–é—®é¢˜

**æ•°æ®åˆ’åˆ†ï¼š**
- è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†åˆ’åˆ†
- **é‡è¦ï¼šç¡®ä¿åŒä¸€å¯¹è¯ä¸è·¨æ•°æ®é›†**
- å¯ä»¥é‡‡æ ·å­é›†è¿›è¡Œå¿«é€Ÿå®éªŒï¼ˆå¦‚5kæ ·æœ¬ï¼‰

### 2.4 Corpuså‡†å¤‡
**QReCCä½¿ç”¨çš„æ˜¯Wikipediaä½œä¸ºæ£€ç´¢åº“**

**é€‰é¡¹1ï¼šä½¿ç”¨é¡¹ç›®ç°æœ‰çš„wiki corpus**
- å·²ä¸‹è½½çš„ `wiki-18.jsonl`
- å·²å»ºç«‹çš„E5ç´¢å¼•

**é€‰é¡¹2ï¼šä½¿ç”¨QReCCå®˜æ–¹æä¾›çš„passage collection**
- å¯èƒ½æ ¼å¼ä¸åŒï¼Œéœ€è¦è½¬æ¢
- å¯èƒ½éœ€è¦é‡æ–°å»ºç«‹ç´¢å¼•

**å»ºè®®ï¼š** å…ˆä½¿ç”¨ç°æœ‰çš„wiki corpusï¼Œä¿æŒä¸€è‡´æ€§

---

## ğŸ”§ é˜¶æ®µä¸‰ï¼šæ¨¡å‹ä¸ç³»ç»Ÿé€‚é…

### 3.1 ä¿®æ”¹Promptç”Ÿæˆé€»è¾‘
**éœ€è¦åˆ›å»ºçš„æ–‡ä»¶ï¼š**
- `scripts/data_process/qrecc_search.py`ï¼ˆå‚è€ƒ `nq_search.py`ï¼‰

**å…³é”®å‡½æ•°ï¼š**
```python
def make_prefix(dp, template_type, conversation_history=None):
    """
    dp: å½“å‰æ•°æ®ç‚¹
    template_type: 'base', 'with_history'
    conversation_history: å¯¹è¯å†å²åˆ—è¡¨
    """
    # å®ç°promptç”Ÿæˆé€»è¾‘
    pass

def format_conversation_history(history, max_turns=5):
    """
    æ ¼å¼åŒ–å¯¹è¯å†å²
    history: [(question, answer), ...]
    max_turns: ä¿ç•™æœ€è¿‘å‡ è½®
    """
    pass
```

### 3.2 è°ƒæ•´è®­ç»ƒé…ç½®
**åˆ›å»ºæ–°çš„è®­ç»ƒè„šæœ¬ï¼š**
- `train_qrecc_ppo.sh`ï¼ˆåŸºäº `train_ppo.sh`ï¼‰

**å…³é”®é…ç½®ä¿®æ”¹ï¼š**
```bash
export DATA_DIR='data/qrecc_search'
export BASE_MODEL='meta-llama/Llama-3.2-3B'
export EXPERIMENT_NAME=qrecc-search-r1-ppo-llama3.2-3b

# éœ€è¦è°ƒæ•´çš„å‚æ•°
data.train_files=$DATA_DIR/train.parquet
data.val_files=$DATA_DIR/test.parquet
data.max_prompt_length=6144  # å¢åŠ ï¼ˆå¯¹è¯å†å²æ›´é•¿ï¼‰
data.max_start_length=3072   # è°ƒæ•´åˆå§‹é•¿åº¦
max_turns=3                  # æ ¹æ®QReCCå¹³å‡å¯¹è¯é•¿åº¦è®¾ç½®
retriever.url="http://127.0.0.1:8000/retrieve"
retriever.topk=3

# å…¶ä»–å‚æ•°å¯å…ˆä¿æŒé»˜è®¤
```

**å‚æ•°è¯´æ˜ï¼š**
- `max_prompt_length`: éœ€è¦å®¹çº³å¯¹è¯å†å²ï¼Œå»ºè®®4096-8192
- `max_start_length`: ç”¨æˆ·è¾“å…¥çš„æœ€å¤§é•¿åº¦
- `max_turns`: RLå…è®¸çš„æœ€å¤§æœç´¢è½®æ¬¡
- `max_response_length`: æ¨¡å‹ç”Ÿæˆçš„æœ€å¤§é•¿åº¦

### 3.3 Rewardå‡½æ•°è®¾è®¡
**åŸºç¡€ç‰ˆæœ¬ï¼ˆå…ˆå®ç°ï¼‰ï¼š**
- æ²¿ç”¨åŸé¡¹ç›®çš„EM (Exact Match)
- ä¸æ ‡å‡†ç­”æ¡ˆåŒ¹é…å³ç»™å¥–åŠ±

**å®ç°ä½ç½®ï¼š**
- æŸ¥çœ‹ `verl/trainer/` æˆ–ç›¸å…³rewardè®¡ç®—é€»è¾‘
- QReCCçš„ç­”æ¡ˆå¯èƒ½æ˜¯åˆ—è¡¨ï¼Œéœ€è¦å¤„ç†

**å¢å¼ºç‰ˆæœ¬ï¼ˆåç»­ä¼˜åŒ–ï¼‰ï¼š**
- **Queryæ”¹å†™è´¨é‡å¥–åŠ±**ï¼šå¯¹æ¯”ç”Ÿæˆçš„queryä¸ground-truth rewrite
- **æ£€ç´¢ç›¸å…³æ€§å¥–åŠ±**ï¼šæ£€ç´¢åˆ°çš„æ–‡æ¡£æ˜¯å¦åŒ…å«ç­”æ¡ˆ
- **å¯¹è¯è¿è´¯æ€§å¥–åŠ±**ï¼šæ˜¯å¦æ­£ç¡®ä½¿ç”¨äº†ä¸Šä¸‹æ–‡
- **å¤šç²’åº¦å¥–åŠ±**ï¼šF1, ROUGE, BERTScoreç­‰

### 3.4 æ£€ç´¢å™¨é…ç½®
**é€‰é¡¹ï¼š**
- å¤ç”¨ç°æœ‰E5æ£€ç´¢å™¨ï¼ˆæ¨èå…ˆç”¨è¿™ä¸ªï¼‰
- æˆ–ä½¿ç”¨æ›´å¼ºçš„å¯¹è¯æ£€ç´¢æ¨¡å‹ï¼ˆå¦‚ConvDRï¼‰

**å¯åŠ¨æ£€ç´¢æœåŠ¡ï¼š**
```bash
conda activate retriever
bash retrieval_launch.sh  # ç¡®è®¤é…ç½®æ­£ç¡®
```

**éªŒè¯æ£€ç´¢æœåŠ¡ï¼š**
```bash
curl -X POST http://127.0.0.1:8000/retrieve \
  -H "Content-Type: application/json" \
  -d '{"query": "who is the president of USA", "topk": 3}'
```

---

## ğŸ§ª é˜¶æ®µå››ï¼šå®éªŒè®¾è®¡

### 4.1 Baselineå®éªŒ
**ç›®çš„ï¼šéªŒè¯ç³»ç»Ÿå¯è¡Œæ€§**

**å®éªŒ1ï¼šä½¿ç”¨æ”¹å†™åçš„queryï¼ˆæ–¹æ¡ˆBï¼‰**
- ç›´æ¥ä½¿ç”¨QReCCæä¾›çš„ `rewrite` å­—æ®µ
- è·³è¿‡æ¨¡å‹å­¦ä¹ æ”¹å†™çš„æ­¥éª¤
- éªŒè¯æ•°æ®å¤„ç†å’Œè®­ç»ƒæµç¨‹æ­£ç¡®æ€§
- **é¢„æœŸç»“æœ**ï¼šæ¨¡å‹åº”è¯¥èƒ½è¾¾åˆ°ä¸NQç±»ä¼¼çš„æ€§èƒ½

**å®éªŒ2ï¼šç®€åŒ–å¯¹è¯å†å²**
- åªä¿ç•™ä¸Šä¸€è½®å¯¹è¯ï¼ˆTurn-1ï¼‰
- é™ä½å¤æ‚åº¦
- **é¢„æœŸç»“æœ**ï¼šéªŒè¯å¯¹è¯å†å²çš„è¡¨ç¤ºæ˜¯å¦æ­£ç¡®

**å®éªŒé…ç½®ï¼š**
- å°è§„æ¨¡æ•°æ®ï¼š5000æ ·æœ¬
- è®­ç»ƒè½®æ•°ï¼š3-5 epochs
- å¿«é€Ÿè¿­ä»£ï¼š1-2å¤©å®Œæˆ

### 4.2 é€æ­¥å¢å¼ºå®éªŒ
**å®éªŒ3ï¼šç«¯åˆ°ç«¯å¯¹è¯ï¼ˆæ–¹æ¡ˆAï¼‰**
- ä½¿ç”¨å®Œæ•´å¯¹è¯å†å²ï¼ˆä¸ç”¨rewriteå­—æ®µï¼‰
- è®©æ¨¡å‹è‡ªå·±å­¦ä¹ æ”¹å†™
- **éš¾åº¦**ï¼šæ›´é«˜
- **é¢„æœŸç»“æœ**ï¼šæ€§èƒ½å¯èƒ½ç•¥ä½äºæ–¹æ¡ˆBï¼Œä½†æ›´å®ç”¨

**å®éªŒ4ï¼šä¸åŒå†å²é•¿åº¦**
- 1è½®å†å² vs 3è½® vs 5è½® vs å…¨éƒ¨å†å²
- åˆ†æå†å²é•¿åº¦çš„å½±å“
- æ‰¾åˆ°æœ€ä¼˜çš„å†å²çª—å£å¤§å°

**å®éªŒ5ï¼šä¸åŒpromptæ¨¡æ¿**
- å¯¹æ¯”ä¸åŒçš„å†å²è¡¨ç¤ºæ–¹å¼
  - æ ¼å¼1ï¼šTurn 1: Q/Aæ ¼å¼
  - æ ¼å¼2ï¼šUser/Assistantæ ¼å¼
  - æ ¼å¼3ï¼šç®€æ´æ ¼å¼ï¼ˆåªæœ‰QAå¯¹ï¼‰
- A/Bæµ‹è¯•æœ€ä½³promptè®¾è®¡

### 4.3 æ¶ˆèå®éªŒ
**éªŒè¯å„ç»„ä»¶çš„ä½œç”¨ï¼š**

| å®éªŒ | å¯¹è¯å†å² | æ”¹å†™Query | æ£€ç´¢ | é¢„æœŸEM |
|------|----------|-----------|------|--------|
| 1    | âŒ       | âœ…        | âœ…   | åŸºçº¿   |
| 2    | âœ…       | âœ…        | âœ…   | æœ€é«˜   |
| 3    | âœ…       | âŒ        | âœ…   | ä¸­ç­‰   |
| 4    | âœ…       | âŒ        | âŒ   | æœ€ä½   |

### 4.4 å¯¹æ¯”å®éªŒ
**ä¸ç°æœ‰æ–¹æ³•å¯¹æ¯”ï¼š**
- Search-R1åœ¨å•è½®NQä¸Šçš„è¡¨ç°
- ç›´æ¥ç”¨æ”¹å†™queryï¼ˆæ–¹æ¡ˆBï¼‰ vs ç«¯åˆ°ç«¯å¯¹è¯ï¼ˆæ–¹æ¡ˆAï¼‰
- ä¸åŒRLç®—æ³•ï¼ˆPPO vs GRPOï¼‰
- ä¸åŒæ¨¡å‹å¤§å°ï¼ˆ3B vs 7Bï¼‰

**å¯¹æ¯”è¡¨æ ¼ç¤ºä¾‹ï¼š**
| æ–¹æ³• | EM | F1 | æ£€ç´¢æ¬¡æ•° | æ¨ç†æ—¶é—´ |
|------|----|----|----------|----------|
| Search-R1 (NQ) | 45.2 | 52.3 | 1.8 | 2.3s |
| Ours (æ–¹æ¡ˆB) | ? | ? | ? | ? |
| Ours (æ–¹æ¡ˆA) | ? | ? | ? | ? |

---

## ğŸ“ é˜¶æ®µäº”ï¼šè¯„ä¼°æŒ‡æ ‡è®¾è®¡

### 5.1 æ ¸å¿ƒæŒ‡æ ‡
**ç­”æ¡ˆè´¨é‡ï¼š**
- **Exact Match (EM)**: ç­”æ¡ˆå®Œå…¨åŒ¹é…çš„æ¯”ä¾‹ï¼ˆä¸»è¦æŒ‡æ ‡ï¼‰
- **F1 Score**: Tokençº§åˆ«çš„F1åˆ†æ•°
- **ROUGE-L**: æœ€é•¿å…¬å…±å­åºåˆ—ç›¸ä¼¼åº¦

**å®ç°ä½ç½®ï¼š**
- å‚è€ƒQReCCå®˜æ–¹è¯„ä¼°è„šæœ¬
- æˆ–ä½¿ç”¨Search-R1ç°æœ‰çš„è¯„ä¼°ä»£ç 

### 5.2 æ£€ç´¢è´¨é‡æŒ‡æ ‡
- **Recall@k**: å‰kä¸ªæ£€ç´¢ç»“æœä¸­åŒ…å«ç­”æ¡ˆçš„æ¯”ä¾‹
- **MRR (Mean Reciprocal Rank)**: ç¬¬ä¸€ä¸ªç›¸å…³æ–‡æ¡£çš„å€’æ•°æ’å
- **æ£€ç´¢æˆåŠŸç‡**: è‡³å°‘æ£€ç´¢åˆ°ä¸€ä¸ªç›¸å…³passageçš„æ¯”ä¾‹

### 5.3 å¯¹è¯ç†è§£æŒ‡æ ‡
- **Queryæ”¹å†™å‡†ç¡®ç‡**: ç”Ÿæˆçš„queryä¸ground-truth rewriteçš„ç›¸ä¼¼åº¦
  - ä½¿ç”¨ROUGEæˆ–BERTScore
  - ä»…é€‚ç”¨äºæ–¹æ¡ˆA
- **æŒ‡ä»£æ¶ˆè§£æˆåŠŸç‡**: æ­£ç¡®å¤„ç†æŒ‡ä»£è¯çš„æ¯”ä¾‹ï¼ˆéœ€è¦äººå·¥æ ‡æ³¨éƒ¨åˆ†æ ·æœ¬ï¼‰

### 5.4 æ•ˆç‡æŒ‡æ ‡
- **å¹³å‡æ£€ç´¢æ¬¡æ•°**: æ¯ä¸ªé—®é¢˜å¹³å‡è°ƒç”¨æ£€ç´¢çš„æ¬¡æ•°
- **æ¨ç†tokenæ•°é‡**: ç”Ÿæˆçš„æ€»tokenæ•°
- **æ¨ç†æ—¶é—´**: ç«¯åˆ°ç«¯å“åº”æ—¶é—´

### 5.5 åˆ†ç»„åˆ†æ
**æŒ‰å¯¹è¯è½®æ¬¡åˆ†æï¼š**
```python
# ç¤ºä¾‹ä»£ç 
results_by_turn = {
    'turn_1': {'em': 0.50, 'f1': 0.58},
    'turn_2-3': {'em': 0.42, 'f1': 0.51},
    'turn_4+': {'em': 0.35, 'f1': 0.45},
}
```

**æŒ‰é—®é¢˜ç±»å‹åˆ†æï¼š**
- æœ‰æŒ‡ä»£ï¼ˆéœ€è¦æ”¹å†™ï¼‰ vs æ— æŒ‡ä»£
- ç®€å•é—®é¢˜ vs å¤æ‚é—®é¢˜
- ç¬¬ä¸€è½® vs åç»­è½®æ¬¡

**è¯„ä¼°è„šæœ¬ä½ç½®ï¼š**
- åˆ›å»º `scripts/evaluate_qrecc.py`

---

## ğŸš€ é˜¶æ®µå…­ï¼šè®­ç»ƒæ‰§è¡Œ

### 6.1 ç¯å¢ƒå‡†å¤‡
**æ£€æŸ¥æ¸…å•ï¼š**
- [ ] GPUèµ„æºç¡®è®¤ï¼ˆè‡³å°‘4-8å¼ GPUï¼Œæ¨è8å¼ ï¼‰
- [ ] ç¯å¢ƒä¾èµ–å®‰è£…
  ```bash
  conda activate searchr1
  pip list | grep vllm  # æ£€æŸ¥ç‰ˆæœ¬
  ```
- [ ] æ•°æ®å­˜å‚¨ç©ºé—´ï¼ˆè‡³å°‘50GBï¼‰
- [ ] æ£€ç´¢æœåŠ¡å™¨éƒ¨ç½²å¹¶éªŒè¯
  ```bash
  # æµ‹è¯•æ£€ç´¢API
  curl -X POST http://127.0.0.1:8000/retrieve \
    -H "Content-Type: application/json" \
    -d '{"query": "test query", "topk": 3}'
  ```
- [ ] wandbè´¦å·é…ç½®
  ```bash
  wandb login
  ```

### 6.2 å°è§„æ¨¡è¯•è¿è¡Œ
**å¿«é€ŸéªŒè¯ï¼ˆ1-2å¤©ï¼‰ï¼š**
- é‡‡æ ·1000æ¡æ•°æ®
- è®­ç»ƒ2-3ä¸ªepoch
- æ£€æŸ¥æ˜¯å¦æœ‰bug
- éªŒè¯è®­ç»ƒæ›²çº¿æ˜¯å¦åˆç†

**è¿è¡Œå‘½ä»¤ï¼š**
```bash
# ä¿®æ”¹train_qrecc_ppo.shä¸­çš„å‚æ•°
data.train_data_num=1000
data.val_data_num=200
trainer.total_epochs=3

bash train_qrecc_ppo.sh
```

**éªŒè¯è¦ç‚¹ï¼š**
- è®­ç»ƒä¸æŠ¥é”™
- Lossæ­£å¸¸ä¸‹é™
- éªŒè¯é›†EMæœ‰æå‡
- æ—¥å¿—æ­£å¸¸è®°å½•åˆ°wandb

### 6.3 å®Œæ•´è®­ç»ƒ
**è®­ç»ƒç­–ç•¥ï¼š**
- **Base Modelé€‰æ‹©**ï¼šå»ºè®®ä» Llama-3.2-3B æˆ– Qwen2.5-3B å¼€å§‹
- **è®­ç»ƒè½®æ•°**ï¼šå‚è€ƒåŸé¡¹ç›®15 epochs
- **Checkpointä¿å­˜**ï¼šæ¯100æ­¥ä¿å­˜ä¸€æ¬¡
- **éªŒè¯é¢‘ç‡**ï¼šæ¯50æ­¥éªŒè¯ä¸€æ¬¡
- **æ—¥å¿—è®°å½•**ï¼šå¼€å¯wandbè¯¦ç»†æ—¥å¿—

**è¿è¡Œå‘½ä»¤ï¼š**
```bash
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
bash train_qrecc_ppo.sh 2>&1 | tee logs/qrecc_train.log
```

**è®­ç»ƒæ—¶é—´ä¼°ç®—ï¼š**
- 3Bæ¨¡å‹ + 8å¡GPU: çº¦1-2å¤©
- 7Bæ¨¡å‹ + 8å¡GPU: çº¦3-5å¤©

**ç›‘æ§è¦ç‚¹ï¼š**
- æ¯ä¸ªepochçš„å¹³å‡reward
- éªŒè¯é›†EMè¶‹åŠ¿
- KLæ•£åº¦ï¼ˆä¸è¦å¤ªå¤§ï¼‰
- GPUåˆ©ç”¨ç‡

### 6.4 è¶…å‚æ•°è°ƒä¼˜
**å…³é”®è¶…å‚æ•°ï¼š**

| å‚æ•° | é»˜è®¤å€¼ | è°ƒä¼˜èŒƒå›´ | è¯´æ˜ |
|------|--------|----------|------|
| actorå­¦ä¹ ç‡ | 1e-6 | 5e-7 ~ 5e-6 | å¤ªå¤§å¯èƒ½ä¸ç¨³å®š |
| criticå­¦ä¹ ç‡ | 1e-5 | 5e-6 ~ 5e-5 | é€šå¸¸æ¯”actorå¤§10å€ |
| KLç³»æ•° | 0.001 | 0.0001 ~ 0.01 | æ§åˆ¶ä¸åŸæ¨¡å‹çš„åç¦» |
| batch_size | 512 | 256 ~ 1024 | å—GPUå†…å­˜é™åˆ¶ |
| max_prompt_length | 6144 | 4096 ~ 8192 | å¯¹è¯å†å²é•¿åº¦ |
| retriever.topk | 3 | 1 ~ 5 | æ£€ç´¢è¿”å›æ•°é‡ |

**è°ƒä¼˜ç­–ç•¥ï¼š**
1. **å…ˆç”¨é»˜è®¤å‚æ•°**ï¼šéªŒè¯æµç¨‹æ­£ç¡®
2. **åŸºäºéªŒè¯é›†è°ƒæ•´**ï¼šæ¯æ¬¡åªæ”¹ä¸€ä¸ªå‚æ•°
3. **è®°å½•æ‰€æœ‰å®éªŒ**ï¼šä½¿ç”¨wandbæˆ–è¡¨æ ¼è®°å½•
4. **å¯é€‰ï¼šè‡ªåŠ¨è°ƒä¼˜**ï¼šä½¿ç”¨Optunaæˆ–Ray Tune

**è°ƒä¼˜å®éªŒç¤ºä¾‹ï¼š**
```bash
# å®éªŒ1ï¼šåŸºçº¿
bash train_qrecc_ppo.sh

# å®éªŒ2ï¼šé™ä½å­¦ä¹ ç‡
# ä¿®æ”¹ actor_rollout_ref.actor.optim.lr=5e-7
bash train_qrecc_ppo.sh

# å®éªŒ3ï¼šå¢åŠ KLç³»æ•°
# ä¿®æ”¹ algorithm.kl_ctrl.kl_coef=0.005
bash train_qrecc_ppo.sh
```

---

## ğŸ“Š é˜¶æ®µä¸ƒï¼šç»“æœåˆ†æä¸ä¼˜åŒ–

### 7.1 å®šé‡åˆ†æ
**å¯¹æ¯”è¡¨æ ¼ï¼š**

| æ–¹æ³• | EM | F1 | Recall@3 | å¹³å‡æ£€ç´¢æ¬¡æ•° | æ¨ç†æ—¶é—´ |
|------|----|----|----------|--------------|----------|
| ConvDR (è®ºæ–‡baseline) | 35.2 | 43.1 | - | - | - |
| Search-R1 (NQå•è½®) | 45.2 | 52.3 | 78.5 | 1.8 | 2.3s |
| Ours (æ”¹å†™query) | ? | ? | ? | ? | ? |
| Ours (ç«¯åˆ°ç«¯) | ? | ? | ? | ? | ? |

**ä¸åŒé…ç½®æ€§èƒ½å¯¹æ¯”ï¼š**
- æŒ‰å¯¹è¯è½®æ¬¡åˆ†ç»„
- æŒ‰å†å²é•¿åº¦åˆ†ç»„
- æŒ‰promptæ¨¡æ¿åˆ†ç»„

### 7.2 å®šæ€§åˆ†æ
**Case Studyï¼ˆæŒ‘é€‰10-20ä¸ªå…¸å‹æ ·æœ¬ï¼‰ï¼š**

**æˆåŠŸæ¡ˆä¾‹åˆ†æï¼š**
```
Conversation:
Turn 1: Q: Who is the president of USA?
         A: Joe Biden
Turn 2: Q: How old is he?
         Model Output: <think>æ ¹æ®ä¸Šæ–‡ï¼Œ"ä»–"æŒ‡çš„æ˜¯Joe Biden</think>
                      <search>Joe Biden age</search>
                      <information>Joe Biden was born on November 20, 1942...</information>
                      <think>è®¡ç®—å¹´é¾„...</think>
                      <answer>81 years old</answer>
         Ground Truth: 81 years old
         Status: âœ… æ­£ç¡®
```

**å¤±è´¥æ¡ˆä¾‹åˆ†æï¼š**
```
Turn 1: Q: What is the capital of France?
         A: Paris
Turn 2: Q: What is its population?
         Model Output: <think>éœ€è¦æŸ¥è¯¢äººå£ä¿¡æ¯</think>
                      <search>population</search>  âŒ queryå¤ªæ¨¡ç³Š
                      <information>è¿”å›æ— å…³å†…å®¹...</information>
                      <answer>Unknown</answer>
         Ground Truth: 2.1 million
         Status: âŒ å¤±è´¥
         åŸå› : æŒ‡ä»£æ¶ˆè§£å¤±è´¥ï¼Œæ²¡æœ‰ç†è§£"its"æŒ‡çš„æ˜¯Paris
```

### 7.3 é”™è¯¯åˆ†æ
**ç»Ÿè®¡é”™è¯¯ç±»å‹åˆ†å¸ƒï¼š**

| é”™è¯¯ç±»å‹ | æ•°é‡ | å æ¯” | ç¤ºä¾‹ |
|----------|------|------|------|
| æŒ‡ä»£æ¶ˆè§£å¤±è´¥ | 150 | 35% | "ä»–"ã€"å®ƒ"ã€"é‚£é‡Œ" |
| æ£€ç´¢queryå¤ªæ¨¡ç³Š | 80 | 19% | "äººå£"è€Œé"Parisäººå£" |
| æ£€ç´¢åˆ°æ— å…³æ–‡æ¡£ | 60 | 14% | queryæ­£ç¡®ä½†æ£€ç´¢å¤±è´¥ |
| æ¨ç†é”™è¯¯ | 50 | 12% | æœ‰æ­£ç¡®ä¿¡æ¯ä½†ç­”æ¡ˆé”™è¯¯ |
| æ ¼å¼é”™è¯¯ | 40 | 9% | ç¼ºå°‘æ ‡ç­¾æˆ–æ ¼å¼ä¸å¯¹ |
| å…¶ä»– | 45 | 11% | - |

**è¯¦ç»†åˆ†ææ¯ç§é”™è¯¯ï¼š**
1. **æŒ‡ä»£æ¶ˆè§£å¤±è´¥**
   - åŸå› ï¼šæ¨¡å‹æ²¡æœ‰æ­£ç¡®ç†è§£å¯¹è¯å†å²
   - è§£å†³æ–¹æ¡ˆï¼šå¢å¼ºpromptã€å¢åŠ å†å²è½®æ¬¡ã€åŠ å…¥ç¤ºä¾‹

2. **æ£€ç´¢queryå¤ªæ¨¡ç³Š**
   - åŸå› ï¼šæ¨¡å‹æ²¡æœ‰å­¦ä¼šæ”¹å†™å®Œæ•´query
   - è§£å†³æ–¹æ¡ˆï¼šå¢åŠ queryæ”¹å†™çš„rewardã€æä¾›æ”¹å†™ç¤ºä¾‹

3. **æ£€ç´¢åˆ°æ— å…³æ–‡æ¡£**
   - åŸå› ï¼šæ£€ç´¢å™¨æ€§èƒ½é—®é¢˜
   - è§£å†³æ–¹æ¡ˆï¼šæ›´æ¢æ£€ç´¢å™¨ã€å¢åŠ rerankerã€è°ƒæ•´topk

### 7.4 è¿­ä»£æ”¹è¿›
**æ ¹æ®åˆ†æç»“æœä¼˜åŒ–ï¼š**

**ä¼˜åŒ–1ï¼šæ”¹è¿›Promptæ¨¡æ¿**
```python
# åŸprompt
"Conversation History:\n{history}\nCurrent Question: {question}"

# æ”¹è¿›promptï¼ˆå¢åŠ æŒ‡ä»£æ¶ˆè§£æŒ‡å¯¼ï¼‰
"""Conversation History:
{history}

Current Question: {question}

Important: If the question contains pronouns (he, she, it, they, there, etc.),
you must first identify what they refer to based on the conversation history,
and use the full entity name in your search query.
"""
```

**ä¼˜åŒ–2ï¼šä¿®æ”¹Rewardå‡½æ•°**
```python
# åŸºç¡€rewardï¼šåªçœ‹ç­”æ¡ˆæ­£ç¡®æ€§
reward = 1.0 if em_match else 0.0

# æ”¹è¿›rewardï¼šå¢åŠ queryè´¨é‡å¥–åŠ±
query_similarity = compute_similarity(generated_query, ground_truth_rewrite)
retrieval_success = check_if_answer_in_retrieved_docs()
reward = 0.6 * em_match + 0.2 * query_similarity + 0.2 * retrieval_success
```

**ä¼˜åŒ–3ï¼šæ”¹è¿›æ£€ç´¢ç­–ç•¥**
- å¢åŠ rerankerï¼ˆä½¿ç”¨ `search_r1/search/rerank_server.py`ï¼‰
- è°ƒæ•´topkï¼ˆ3 â†’ 5ï¼‰
- å°è¯•dense + sparseæ··åˆæ£€ç´¢

**ä¼˜åŒ–4ï¼šæ•°æ®å¢å¼º**
- æ·»åŠ few-shotç¤ºä¾‹åœ¨promptä¸­
- åˆæˆæ›´å¤šå¯¹è¯æ•°æ®ï¼ˆç”¨GPT-4ï¼‰
- ä»å¤±è´¥æ¡ˆä¾‹ä¸­å­¦ä¹ 

**é‡æ–°è®­ç»ƒå¹¶å¯¹æ¯”ï¼š**
```bash
# è®°å½•ä¼˜åŒ–å‰çš„ç»“æœ
baseline_em = 42.5

# åº”ç”¨ä¼˜åŒ–åé‡æ–°è®­ç»ƒ
bash train_qrecc_ppo_v2.sh

# å¯¹æ¯”ç»“æœ
improved_em = 47.8  # +5.3æå‡
```

---

## ğŸ¯ é˜¶æ®µå…«ï¼šè¿›é˜¶ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰

### 8.1 Queryæ”¹å†™å¢å¼º
**æ˜¾å¼æ”¹å†™æ¨¡å—ï¼š**
- è®©æ¨¡å‹å…ˆç”Ÿæˆæ”¹å†™queryï¼ˆåœ¨ `<rewrite>` æ ‡ç­¾ä¸­ï¼‰
- å†æ‰§è¡Œæ£€ç´¢
- å¯ä»¥ä¸ground-truthæ”¹å†™ç›‘ç£å­¦ä¹ ç»“åˆ

**å®ç°æ–¹å¼ï¼š**
```python
# ä¿®æ”¹prompt
"""
If the current question contains references to previous context,
first rewrite it as a standalone question in <rewrite></rewrite>.
Then use the rewritten question to search.

Example:
Turn 1: Q: Who is the CEO of Apple?
Turn 2: Q: How old is he?
         <rewrite>How old is the CEO of Apple?</rewrite>
         <search>CEO of Apple age</search>
"""
```

**Rewardè®¾è®¡ï¼š**
- å¦‚æœç”Ÿæˆäº† `<rewrite>` æ ‡ç­¾ï¼Œè®¡ç®—ä¸ground-truthçš„ç›¸ä¼¼åº¦
- ç»™äºˆé¢å¤–å¥–åŠ±

### 8.2 æ£€ç´¢ç­–ç•¥ä¼˜åŒ–
**åŠ¨æ€æ£€ç´¢ï¼š**
- æ ¹æ®é—®é¢˜å¤æ‚åº¦è°ƒæ•´topk
- ç®€å•é—®é¢˜topk=1ï¼Œå¤æ‚é—®é¢˜topk=5
- è‡ªé€‚åº”å†³å®šæ˜¯å¦éœ€è¦æ£€ç´¢ï¼ˆæœ‰äº›é—®é¢˜åŸºäºå¯¹è¯å†å²å°±èƒ½å›ç­”ï¼‰

**å¤šæ ·æ€§æ£€ç´¢ï¼š**
- é¿å…æ£€ç´¢åˆ°é‡å¤ä¿¡æ¯
- ä½¿ç”¨MMR (Maximal Marginal Relevance)

**è¿­ä»£æ£€ç´¢ï¼š**
- ç¬¬ä¸€æ¬¡æ£€ç´¢åï¼Œæ ¹æ®ç»“æœç”Ÿæˆæ–°çš„query
- å¤šæ¬¡æ£€ç´¢å¹¶èåˆä¿¡æ¯

### 8.3 å¤šä»»åŠ¡å­¦ä¹ 
**è”åˆè®­ç»ƒNQå’ŒQReCCï¼š**
- åŒæ—¶ä½¿ç”¨ä¸¤ä¸ªæ•°æ®é›†
- æå‡æ³›åŒ–èƒ½åŠ›
- åœ¨ä¸åŒä»»åŠ¡é—´è¿ç§»èƒ½åŠ›

**å®ç°æ–¹å¼ï¼š**
```bash
# åˆå¹¶æ•°æ®é›†
python scripts/data_process/merge_datasets.py \
  --datasets nq qrecc \
  --output data/multitask/

# è®­ç»ƒ
bash train_multitask_ppo.sh
```

### 8.4 æ¨¡å‹è’¸é¦
**ç”¨å¤§æ¨¡å‹æŒ‡å¯¼å°æ¨¡å‹ï¼š**

**æ­¥éª¤1ï¼šè®­ç»ƒå¤§æ¨¡å‹**
```bash
# å…ˆè®­ç»ƒ7Bæ¨¡å‹
export BASE_MODEL='meta-llama/Llama-3.1-8B'
bash train_qrecc_ppo.sh
```

**æ­¥éª¤2ï¼šç”Ÿæˆè’¸é¦æ•°æ®**
```python
# ç”¨7Bæ¨¡å‹ç”Ÿæˆæ¨ç†è¿‡ç¨‹
# æå–æ€ç»´é“¾ã€æ£€ç´¢queryç­‰
```

**æ­¥éª¤3ï¼šè’¸é¦åˆ°å°æ¨¡å‹**
```bash
# ç”¨3Bæ¨¡å‹å­¦ä¹ 7Bæ¨¡å‹çš„è¡Œä¸º
# å¯ä»¥ç”¨SFTæˆ–ç»§ç»­RL
```

### 8.5 æ·»åŠ Reranker
**ä½¿ç”¨Cross-Encoderé‡æ’åºï¼š**
```bash
# å¯åŠ¨rerankeræœåŠ¡å™¨
conda activate retriever
python search_r1/search/rerank_server.py \
  --model cross-encoder/ms-marco-MiniLM-L-12-v2 \
  --port 8001
```

**ä¿®æ”¹è®­ç»ƒé…ç½®ï¼š**
```bash
# train_qrecc_ppo.sh
retriever.rerank_url="http://127.0.0.1:8001/rerank"
retriever.rerank_topk=3
```

### 8.6 Few-shot Prompting
**åœ¨promptä¸­æ·»åŠ ç¤ºä¾‹ï¼š**
```python
prompt = """
Answer the question based on conversation history.

Example 1:
History:
Turn 1: Q: Who is the CEO of Tesla?
        A: Elon Musk
Current Question: Where was he born?
Output:
<think>Based on the history, "he" refers to Elon Musk</think>
<search>Elon Musk birthplace</search>
<information>Elon Musk was born in Pretoria, South Africa...</information>
<answer>Pretoria, South Africa</answer>

Example 2:
...

Now your turn:
History:
{conversation_history}
Current Question: {question}
"""
```

---

## ğŸ“ é˜¶æ®µä¹ï¼šæ–‡æ¡£ä¸æ€»ç»“

### 9.1 ä»£ç ç»„ç»‡
**æ¨èç›®å½•ç»“æ„ï¼š**
```
Search-R1/
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ qrecc_implementation_plan.md  # æœ¬æ–‡æ¡£
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_process/
â”‚   â”‚   â”œâ”€â”€ nq_search.py              # åŸæœ‰çš„
â”‚   â”‚   â””â”€â”€ qrecc_search.py           # æ–°å»º - QReCCæ•°æ®å¤„ç†
â”‚   â””â”€â”€ evaluate/
â”‚       â””â”€â”€ evaluate_qrecc.py         # æ–°å»º - QReCCè¯„ä¼°è„šæœ¬
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ train_qrecc_ppo.sh            # æ–°å»º - QReCCè®­ç»ƒé…ç½®
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ nq_search/                    # åŸæœ‰çš„
â”‚   â””â”€â”€ qrecc_search/                 # æ–°å»º
â”‚       â”œâ”€â”€ train.parquet
â”‚       â”œâ”€â”€ test.parquet
â”‚       â””â”€â”€ README.md                 # æ•°æ®è¯´æ˜
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ qrecc_results/                # æ–°å»º - å®éªŒç»“æœ
â”‚       â”œâ”€â”€ baseline/
â”‚       â”œâ”€â”€ with_history/
â”‚       â””â”€â”€ analysis.md
â””â”€â”€ verl_checkpoints/
    â””â”€â”€ qrecc-search-r1-*/            # è®­ç»ƒcheckpoint
```

### 9.2 å®éªŒè®°å½•
**ä½¿ç”¨wandbè®°å½•æ‰€æœ‰å®éªŒï¼š**
- é¡¹ç›®åç§°ï¼š`Search-R1-QReCC`
- æ¯ä¸ªå®éªŒçš„å‘½åè§„èŒƒï¼š`qrecc-{model}-{method}-{date}`
- è®°å½•å†…å®¹ï¼š
  - è®­ç»ƒæ›²çº¿ï¼ˆloss, reward, KLï¼‰
  - éªŒè¯é›†æ€§èƒ½ï¼ˆEM, F1ï¼‰
  - è¶…å‚æ•°é…ç½®
  - æ¯ä¸ªcheckpointçš„æ€§èƒ½

**æœ¬åœ°å®éªŒè¡¨æ ¼ï¼ˆexperiments/qrecc_results/experiments.mdï¼‰ï¼š**
```markdown
| å®éªŒID | æ—¥æœŸ | æ¨¡å‹ | æ–¹æ³• | EM | F1 | å¤‡æ³¨ |
|--------|------|------|------|----|----|------|
| exp001 | 2025-01-15 | Llama-3.2-3B | æ”¹å†™query | 43.2 | 50.1 | baseline |
| exp002 | 2025-01-16 | Llama-3.2-3B | ç«¯åˆ°ç«¯ | 39.8 | 47.3 | éœ€è¦è°ƒä¼˜ |
| exp003 | 2025-01-17 | Llama-3.2-3B | ç«¯åˆ°ç«¯+ä¼˜åŒ–prompt | 42.1 | 49.5 | æ”¹è¿› |
| ... | ... | ... | ... | ... | ... | ... |
```

### 9.3 æ’°å†™é¡¹ç›®README
**åˆ›å»º `data/qrecc_search/README.md`ï¼š**
```markdown
# QReCC Search Dataset for Search-R1

## æ•°æ®é›†ä»‹ç»
QReCC (Question Rewriting in Conversational Context) æ˜¯ä¸€ä¸ªå¯¹è¯å¼é—®ç­”æ•°æ®é›†...

## æ•°æ®å¤„ç†
ä½¿ç”¨ `scripts/data_process/qrecc_search.py` å¤„ç†åŸå§‹æ•°æ®ã€‚

å¤„ç†æ­¥éª¤ï¼š
1. ä¸‹è½½åŸå§‹æ•°æ®
2. æŒ‰å¯¹è¯åˆ†ç»„
3. æ„å»ºå¯¹è¯å†å²
4. ç”Ÿæˆè®­ç»ƒæ ·æœ¬

## æ•°æ®æ ¼å¼
æ¯æ¡æ•°æ®åŒ…å«ï¼š
- data_source: "qrecc"
- prompt: åŒ…å«å¯¹è¯å†å²çš„æç¤º
- ability: "conversational-reasoning"
- reward_model: ç­”æ¡ˆåŒ¹é…è§„åˆ™
- extra_info: å¯¹è¯å…ƒä¿¡æ¯

## ä½¿ç”¨æ–¹æ³•
```bash
# æ•°æ®å¤„ç†
python scripts/data_process/qrecc_search.py

# è®­ç»ƒ
bash configs/train_qrecc_ppo.sh

# è¯„ä¼°
python scripts/evaluate/evaluate_qrecc.py
```

## ç»Ÿè®¡ä¿¡æ¯
- è®­ç»ƒé›†: ~11kä¸ªå¯¹è¯ï¼Œ~50kä¸ªturn
- æµ‹è¯•é›†: ~1kä¸ªå¯¹è¯ï¼Œ~5kä¸ªturn
- å¹³å‡å¯¹è¯é•¿åº¦: 4.5è½®
- å¹³å‡é—®é¢˜é•¿åº¦: 8.3 tokens
```

### 9.4 æ’°å†™å®éªŒæŠ¥å‘Š
**åˆ›å»º `experiments/qrecc_results/report.md`ï¼š**

åŒ…å«å†…å®¹ï¼š
1. **é¡¹ç›®èƒŒæ™¯**
   - åŠ¨æœºï¼šä¸ºä»€ä¹ˆåšQReCC
   - æŒ‘æˆ˜ï¼šå¯¹è¯å¼æ£€ç´¢çš„éš¾ç‚¹

2. **æ–¹æ³•ä»‹ç»**
   - æ•°æ®å¤„ç†æµç¨‹
   - æ¨¡å‹æ¶æ„
   - è®­ç»ƒæ–¹æ³•

3. **å®éªŒè®¾ç½®**
   - æ•°æ®é›†è§„æ¨¡
   - è¶…å‚æ•°é…ç½®
   - è®­ç»ƒç¯å¢ƒ

4. **å®éªŒç»“æœ**
   - ä¸»è¦ç»“æœè¡¨æ ¼
   - æ¶ˆèå®éªŒ
   - å¯¹æ¯”å®éªŒ

5. **åˆ†æè®¨è®º**
   - å®šé‡åˆ†æ
   - å®šæ€§åˆ†æï¼ˆcase studyï¼‰
   - é”™è¯¯åˆ†æ

6. **ç»“è®ºä¸æœªæ¥å·¥ä½œ**
   - ä¸»è¦è´¡çŒ®
   - å±€é™æ€§
   - æœªæ¥æ”¹è¿›æ–¹å‘

---

## âš ï¸ é¢„æœŸæŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ

### æŒ‘æˆ˜1ï¼šå¯¹è¯å†å²è¿‡é•¿
**é—®é¢˜ï¼š** å®Œæ•´å¯¹è¯å†å²å¯èƒ½è¶…è¿‡æ¨¡å‹æœ€å¤§é•¿åº¦é™åˆ¶ï¼ˆå¦‚4096 tokensï¼‰

**è§£å†³æ–¹æ¡ˆï¼š**
- **æ–¹æ¡ˆAï¼šæˆªæ–­æ—©æœŸå†å²**
  - åªä¿ç•™æœ€è¿‘Nè½®ï¼ˆN=3~5ï¼‰
  - å®ç°ï¼šæ»‘åŠ¨çª—å£

- **æ–¹æ¡ˆBï¼šæ‘˜è¦å‹ç¼©å†å²**
  - ç”¨æ¨¡å‹æ€»ç»“æ—©æœŸå¯¹è¯
  - å®ç°ï¼šç”¨GPT-4æˆ–å°æ¨¡å‹ç”Ÿæˆæ‘˜è¦

- **æ–¹æ¡ˆCï¼šåŠ¨æ€é€‰æ‹©**
  - æ ¹æ®é‡è¦æ€§é€‰æ‹©ä¿ç•™å“ªäº›è½®æ¬¡
  - å®ç°ï¼šç”¨ç›¸ä¼¼åº¦ç­›é€‰ç›¸å…³å†å²

**ä»£ç ç¤ºä¾‹ï¼š**
```python
def truncate_history(history, max_turns=5):
    """ä¿ç•™æœ€è¿‘max_turnsè½®"""
    return history[-max_turns:]
```

### æŒ‘æˆ˜2ï¼šè®­ç»ƒä¸ç¨³å®š
**é—®é¢˜ï¼š** RLè®­ç»ƒå¯èƒ½ä¸æ”¶æ•›ï¼Œrewardéœ‡è¡

**è§£å†³æ–¹æ¡ˆï¼š**
- **é™ä½å­¦ä¹ ç‡**ï¼šä»1e-6é™åˆ°5e-7
- **å¢åŠ warmup**ï¼š`lr_warmup_steps_ratio=0.3`
- **å°è¯•GRPO**ï¼šæ¯”PPOæ›´ç¨³å®š
  ```bash
  bash train_qrecc_grpo.sh  # ä½¿ç”¨GRPOç®—æ³•
  ```
- **å…ˆç”¨SFTé¢„è®­ç»ƒ**ï¼š
  - ç”¨å°‘é‡äººå·¥æ ‡æ³¨æ•°æ®åšç›‘ç£å­¦ä¹ 
  - å†ç”¨RLå¾®è°ƒ

### æŒ‘æˆ˜3ï¼šæ£€ç´¢æ•ˆç‡ä½
**é—®é¢˜ï¼š** å¯¹è¯å¼æ£€ç´¢éœ€è¦é¢‘ç¹è°ƒç”¨ï¼Œå»¶è¿Ÿé«˜

**è§£å†³æ–¹æ¡ˆï¼š**
- **ä½¿ç”¨ANNç´¢å¼•**ï¼š
  - ä»Flatç´¢å¼•åˆ‡æ¢åˆ°IVFæˆ–HNSW
  - å‚è€ƒ `search_r1/search/index_builder.py`

- **æ‰¹é‡æ£€ç´¢**ï¼š
  - ä¸€æ¬¡æ€§æ£€ç´¢å¤šä¸ªquery
  - ä¿®æ”¹æ£€ç´¢APIæ”¯æŒbatch

- **ç¼“å­˜æœºåˆ¶**ï¼š
  - ç¼“å­˜çƒ­é—¨queryçš„ç»“æœ
  - ä½¿ç”¨Redisæˆ–å†…å­˜ç¼“å­˜

### æŒ‘æˆ˜4ï¼šè¯„ä¼°å›°éš¾
**é—®é¢˜ï¼š** å¯¹è¯è´¨é‡éš¾ä»¥ç”¨å•ä¸€æŒ‡æ ‡é‡åŒ–

**è§£å†³æ–¹æ¡ˆï¼š**
- **å¤šæŒ‡æ ‡ç»¼åˆè¯„ä¼°**ï¼š
  - EMï¼ˆä¸»è¦ï¼‰
  - F1ã€ROUGEï¼ˆè¾…åŠ©ï¼‰
  - Queryè´¨é‡ï¼ˆæ”¹å†™ç›¸ä¼¼åº¦ï¼‰
  - æ£€ç´¢è´¨é‡ï¼ˆRecallï¼‰

- **äººå·¥è¯„æµ‹**ï¼š
  - éšæœºé‡‡æ ·100ä¸ªæ ·æœ¬
  - äººå·¥è¯„ä¼°ï¼šæ­£ç¡®æ€§ã€è¿è´¯æ€§ã€å¯è§£é‡Šæ€§

- **ä¸baselineè¯¦ç»†å¯¹æ¯”**ï¼š
  - ä¸ä»…æ¯”æ€»ä½“æ€§èƒ½
  - è¿˜è¦æŒ‰è½®æ¬¡ã€é—®é¢˜ç±»å‹åˆ†ç»„å¯¹æ¯”

### æŒ‘æˆ˜5ï¼šæ•°æ®å¤„ç†å¤æ‚
**é—®é¢˜ï¼š** QReCCçš„å¯¹è¯ç»“æ„å¤æ‚ï¼Œå¤„ç†å®¹æ˜“å‡ºé”™

**è§£å†³æ–¹æ¡ˆï¼š**
- **å•å…ƒæµ‹è¯•**ï¼š
  ```python
  def test_process_conversation():
      # æµ‹è¯•å¯¹è¯å¤„ç†æ˜¯å¦æ­£ç¡®
      sample = {...}
      result = process_conversation(sample)
      assert result['prompt'][0]['content'].startswith("History:")
  ```

- **å¯è§†åŒ–éªŒè¯**ï¼š
  ```python
  # æ‰“å°å¤„ç†åçš„æ ·æœ¬
  for i in range(5):
      print(f"=== Sample {i} ===")
      print(processed_data[i])
  ```

- **å°è§„æ¨¡éªŒè¯**ï¼š
  - å…ˆå¤„ç†100æ¡æ•°æ®
  - æ‰‹å·¥æ£€æŸ¥æ˜¯å¦æ­£ç¡®
  - å†å¤„ç†å®Œæ•´æ•°æ®

### æŒ‘æˆ˜6ï¼šRewardè®¾è®¡å›°éš¾
**é—®é¢˜ï¼š** ç®€å•çš„EMå¯èƒ½ä¸è¶³ä»¥å¼•å¯¼æ¨¡å‹å­¦ä¹ queryæ”¹å†™

**è§£å†³æ–¹æ¡ˆï¼š**
- **åˆ†é˜¶æ®µreward**ï¼š
  - é˜¶æ®µ1ï¼šåªç”¨EMï¼ˆéªŒè¯å¯è¡Œæ€§ï¼‰
  - é˜¶æ®µ2ï¼šåŠ å…¥queryæ”¹å†™reward
  - é˜¶æ®µ3ï¼šåŠ å…¥æ£€ç´¢ç›¸å…³æ€§reward

- **Reward shaping**ï¼š
  ```python
  # åŸºç¡€reward
  reward = 1.0 if em_match else 0.0

  # ä¸­é—´æ­¥éª¤å¥–åŠ±
  if '<rewrite>' in output:
      rewrite_quality = compute_similarity(...)
      reward += 0.2 * rewrite_quality

  if answer_in_retrieved_docs:
      reward += 0.1
  ```

- **ä»ç®€å•åˆ°å¤æ‚**ï¼š
  - å…ˆç”¨ç¨€ç–rewardï¼ˆåªçœ‹æœ€ç»ˆç­”æ¡ˆï¼‰
  - æ¨¡å‹æœ‰ä¸€å®šèƒ½åŠ›åï¼Œå†åŠ å…¥å¯†é›†reward

---

## ğŸ“ å­¦ä¹ ä¸å‚è€ƒèµ„æº

### å¿…è¯»è®ºæ–‡
1. **QReCCåŸè®ºæ–‡**
   - Anantha et al. "Open-Domain Question Answering Goes Conversational via Question Rewriting" (NAACL 2021)
   - ç†è§£æ•°æ®é›†è®¾è®¡å’Œbaselineæ–¹æ³•

2. **Search-R1è®ºæ–‡**
   - Jin et al. "Search-R1: Training LLMs to Reason and Leverage Search Engines with RL" (2025)
   - ç†è§£RLè®­ç»ƒç»†èŠ‚å’Œrewardè®¾è®¡

3. **ConvDR (å¯¹è¯å¼Dense Retrieval)**
   - Yu et al. "ConvDR: Conversational Dense Retrieval" (SIGIR 2021)
   - å¯¹è¯å¼æ£€ç´¢çš„SOTAæ–¹æ³•

4. **ç›¸å…³å·¥ä½œ**
   - DeepSeek-R1: æ¨ç†å’ŒRLè®­ç»ƒ
   - RAGEN: RAGçš„RLè®­ç»ƒ
   - PPO/GRPOç®—æ³•åŸç†

### æ¨èä»£ç åº“
1. **åŸSearch-R1ä»£ç **
   - `scripts/data_process/nq_search.py` - æ•°æ®å¤„ç†ç¤ºä¾‹
   - `train_ppo.sh` - è®­ç»ƒé…ç½®ç¤ºä¾‹
   - `verl/trainer/` - RLè®­ç»ƒé€»è¾‘

2. **veRLæ–‡æ¡£**
   - https://verl.readthedocs.io/
   - å¤šè½®å¯¹è¯ç¤ºä¾‹

3. **QReCCå®˜æ–¹ä»£ç **
   - https://github.com/apple/ml-qrecc
   - è¯„ä¼°è„šæœ¬å’Œbaseline

### åœ¨çº¿èµ„æº
- **HuggingFace QReCCé¡µé¢**: æ•°æ®é›†æ–‡æ¡£
- **wandb Search-R1é¡¹ç›®**: åŸé¡¹ç›®çš„è®­ç»ƒæ—¥å¿—
- **è®ºæ–‡è§£è¯»è§†é¢‘/åšå®¢**: æœç´¢Search-R1å’ŒQReCC

---

## âœ… é‡Œç¨‹ç¢‘æ£€æŸ¥æ¸…å•

### ç¬¬1å‘¨ï¼šå‡†å¤‡ä¸æ¢ç´¢
- [ ] ä¸‹è½½å¹¶æ¢ç´¢QReCCæ•°æ®é›†
- [ ] é˜…è¯»QReCCè®ºæ–‡å’ŒSearch-R1è®ºæ–‡
- [ ] ç†è§£æ•°æ®é›†ç»“æ„å’Œå­—æ®µ
- [ ] ç»Ÿè®¡æ•°æ®é›†ç‰¹å¾ï¼ˆå¯¹è¯é•¿åº¦åˆ†å¸ƒç­‰ï¼‰
- [ ] ç¡®å®šæŠ€æœ¯è·¯çº¿ï¼ˆæ–¹æ¡ˆA/Bï¼‰

### ç¬¬2å‘¨ï¼šæ•°æ®å¤„ç†
- [ ] è®¾è®¡æ•°æ®schemaå’Œpromptæ¨¡æ¿
- [ ] ç¼–å†™æ•°æ®å¤„ç†è„šæœ¬ `qrecc_search.py`
- [ ] å¤„ç†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
- [ ] éªŒè¯å¤„ç†åçš„æ•°æ®ï¼ˆå¯è§†åŒ–æ£€æŸ¥ï¼‰
- [ ] å‡†å¤‡æ£€ç´¢corpusï¼ˆå¤ç”¨æˆ–æ–°å»ºï¼‰

### ç¬¬3å‘¨ï¼šç³»ç»Ÿé€‚é…
- [ ] åˆ›å»ºè®­ç»ƒé…ç½® `train_qrecc_ppo.sh`
- [ ] è°ƒæ•´è¶…å‚æ•°é…ç½®
- [ ] å¯åŠ¨æ£€ç´¢æœåŠ¡å™¨å¹¶éªŒè¯
- [ ] é…ç½®wandbæ—¥å¿—
- [ ] å°è§„æ¨¡è¯•è¿è¡Œï¼ˆ1000æ ·æœ¬ï¼‰

### ç¬¬4å‘¨ï¼šBaselineå®éªŒ
- [ ] å®éªŒ1ï¼šä½¿ç”¨æ”¹å†™queryï¼ˆæ–¹æ¡ˆBï¼‰
- [ ] å®éªŒ2ï¼šç®€åŒ–å¯¹è¯å†å²
- [ ] éªŒè¯è®­ç»ƒæµç¨‹æ­£ç¡®æ€§
- [ ] åˆæ­¥ç»“æœåˆ†æ
- [ ] è°ƒè¯•å’Œä¿®å¤é—®é¢˜

### ç¬¬5-6å‘¨ï¼šå®Œæ•´è®­ç»ƒ
- [ ] å®Œæ•´æ•°æ®è®­ç»ƒï¼ˆæ–¹æ¡ˆBï¼‰
- [ ] ç›‘æ§è®­ç»ƒè¿‡ç¨‹
- [ ] ä¿å­˜æœ€ä½³checkpoint
- [ ] åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
- [ ] è®°å½•baselineæ€§èƒ½

### ç¬¬7å‘¨ï¼šè¿›é˜¶å®éªŒ
- [ ] å®éªŒ3ï¼šç«¯åˆ°ç«¯å¯¹è¯ï¼ˆæ–¹æ¡ˆAï¼‰
- [ ] å®éªŒ4ï¼šä¸åŒå†å²é•¿åº¦
- [ ] å®éªŒ5ï¼šä¸åŒpromptæ¨¡æ¿
- [ ] å¯¹æ¯”å„å®éªŒç»“æœ
- [ ] é€‰æ‹©æœ€ä½³é…ç½®

### ç¬¬8å‘¨ï¼šæ¶ˆèä¸å¯¹æ¯”
- [ ] æ¶ˆèå®éªŒï¼ˆæœ‰æ— å†å²ã€æœ‰æ— æ”¹å†™ç­‰ï¼‰
- [ ] ä¸NQå•è½®ç»“æœå¯¹æ¯”
- [ ] ä¸è®ºæ–‡baselineå¯¹æ¯”
- [ ] ä¸åŒRLç®—æ³•å¯¹æ¯”ï¼ˆPPO vs GRPOï¼‰
- [ ] æ•´ç†å¯¹æ¯”è¡¨æ ¼

### ç¬¬9å‘¨ï¼šæ·±å…¥åˆ†æ
- [ ] å®šé‡åˆ†æï¼ˆæŒ‰è½®æ¬¡ã€æŒ‰ç±»å‹ï¼‰
- [ ] å®šæ€§åˆ†æï¼ˆcase studyï¼‰
- [ ] é”™è¯¯åˆ†æï¼ˆç»Ÿè®¡é”™è¯¯ç±»å‹ï¼‰
- [ ] è¯†åˆ«ä¸»è¦é—®é¢˜
- [ ] åˆ¶å®šä¼˜åŒ–æ–¹æ¡ˆ

### ç¬¬10å‘¨ï¼šè¿­ä»£ä¼˜åŒ–
- [ ] ä¼˜åŒ–promptæ¨¡æ¿
- [ ] æ”¹è¿›rewardå‡½æ•°
- [ ] å°è¯•reranker
- [ ] é‡æ–°è®­ç»ƒ
- [ ] éªŒè¯æ”¹è¿›æ•ˆæœ

### ç¬¬11-12å‘¨ï¼šæ–‡æ¡£ä¸æ€»ç»“
- [ ] æ’°å†™é¡¹ç›®README
- [ ] æ•´ç†å®éªŒè®°å½•
- [ ] ç¼–å†™å®éªŒæŠ¥å‘Š
- [ ] å‡†å¤‡æ¼”ç¤ºdemoï¼ˆå¯é€‰ï¼‰
- [ ] ä»£ç æ¸…ç†å’Œæ³¨é‡Š

---

## ğŸ¯ ä¸‰ç§æ¨è¿›ç­–ç•¥

### ç­–ç•¥1ï¼šå¿«é€Ÿè¿­ä»£ï¼ˆ2-3å‘¨ï¼‰
**é€‚åˆï¼šå¿«é€ŸéªŒè¯æƒ³æ³•ã€æ—¶é—´ç´§å¼ **

**é‡Œç¨‹ç¢‘ï¼š**
- Week 1: æ•°æ®å¤„ç† + ç³»ç»Ÿé€‚é…
- Week 2: Baselineè®­ç»ƒï¼ˆæ–¹æ¡ˆBï¼Œ5kæ ·æœ¬ï¼‰
- Week 3: è¯„ä¼° + ç®€å•ä¼˜åŒ–

**äº¤ä»˜ç‰©ï¼š**
- åŸºç¡€ä»£ç å’Œæ•°æ®
- åˆæ­¥å®éªŒç»“æœ
- ç®€çŸ­æŠ¥å‘Š

### ç­–ç•¥2ï¼šå®Œæ•´å®æ–½ï¼ˆ4-6å‘¨ï¼‰
**é€‚åˆï¼šè¯¾ç¨‹é¡¹ç›®ã€æ¯•ä¸šè®¾è®¡**

**é‡Œç¨‹ç¢‘ï¼š**
- Week 1-2: æ•°æ®å¤„ç† + Baseline
- Week 3-4: å®Œæ•´è®­ç»ƒ + è¿›é˜¶å®éªŒ
- Week 5: åˆ†æä¼˜åŒ–
- Week 6: æ–‡æ¡£æ€»ç»“

**äº¤ä»˜ç‰©ï¼š**
- å®Œæ•´ä»£ç å’Œæ–‡æ¡£
- å¤šç»„å¯¹æ¯”å®éªŒ
- è¯¦ç»†åˆ†ææŠ¥å‘Š
- å¯è¿è¡Œçš„demo

### ç­–ç•¥3ï¼šè®ºæ–‡çº§ï¼ˆ8-12å‘¨ï¼‰
**é€‚åˆï¼šå‘è¡¨è®ºæ–‡ã€æ·±å…¥ç ”ç©¶**

**é‡Œç¨‹ç¢‘ï¼š**
- Week 1-2: æ–‡çŒ®è°ƒç ” + æ•°æ®å‡†å¤‡
- Week 3-4: Baselineå®éªŒ
- Week 5-6: å¤šç»„å¯¹æ¯”å®éªŒ
- Week 7-8: åˆ›æ–°æ–¹æ³•å®ç°
- Week 9-10: æ·±å…¥åˆ†æä¼˜åŒ–
- Week 11-12: è®ºæ–‡æ’°å†™

**äº¤ä»˜ç‰©ï¼š**
- ç ”ç©¶çº§ä»£ç 
- å…¨é¢çš„å®éªŒ
- åˆ›æ–°çš„æ–¹æ³•
- å­¦æœ¯è®ºæ–‡è‰ç¨¿

---

## ğŸ’¡ æˆåŠŸå…³é”®è¦ç´ 

### 1. å¾ªåºæ¸è¿›
- ä¸è¦ä¸€å¼€å§‹å°±åšæœ€å¤æ‚çš„
- å…ˆéªŒè¯baselineï¼Œå†é€æ­¥å¢å¼º
- æ¯ä¸ªé˜¶æ®µéƒ½æœ‰æ˜ç¡®ç›®æ ‡

### 2. è¯¦ç»†è®°å½•
- è®°å½•æ¯ä¸ªå®éªŒçš„é…ç½®å’Œç»“æœ
- ä½¿ç”¨wandbè‡ªåŠ¨è®°å½•è®­ç»ƒè¿‡ç¨‹
- ä¿å­˜ä»£ç ç‰ˆæœ¬ï¼ˆgit commitï¼‰

### 3. åŠæ—¶åˆ†æ
- ä¸è¦ç›²ç›®è°ƒå‚
- æ¯ä¸ªå®éªŒåéƒ½è¦åˆ†æåŸå› 
- åŸºäºåˆ†æç»“æœè°ƒæ•´ç­–ç•¥

### 4. é€‚æ—¶æ±‚åŠ©
- é‡åˆ°bugåŠæ—¶æŸ¥æ–‡æ¡£/issue
- å…³é”®å†³ç­–å¯ä»¥å’¨è¯¢å¯¼å¸ˆ/åŒå­¦
- åˆ©ç”¨å¼€æºç¤¾åŒºèµ„æº

### 5. ä¿æŒçµæ´»
- å¦‚æœæŸä¸ªæ–¹å‘è¡Œä¸é€šï¼ŒåŠæ—¶è°ƒæ•´
- æ ¹æ®èµ„æºé™åˆ¶é€‰æ‹©åˆé€‚çš„è§„æ¨¡
- ä¸å¿…æ‹˜æ³¥äºåŸè®¡åˆ’

---

## ğŸ“ é—®é¢˜è¯Šæ–­æ¸…å•

**å¦‚æœè®­ç»ƒä¸æ”¶æ•›ï¼š**
- [ ] æ£€æŸ¥æ•°æ®å¤„ç†æ˜¯å¦æ­£ç¡®ï¼ˆæ‰“å°å‡ ä¸ªæ ·æœ¬ï¼‰
- [ ] é™ä½å­¦ä¹ ç‡ï¼ˆå‡åŠï¼‰
- [ ] æ£€æŸ¥rewardæ˜¯å¦åˆç†ï¼ˆæ‰“å°å‡ ä¸ªrewardå€¼ï¼‰
- [ ] å°è¯•æ›´ç¨³å®šçš„ç®—æ³•ï¼ˆGRPOï¼‰
- [ ] å‡å°‘KLç³»æ•°

**å¦‚æœæ€§èƒ½ä¸ç†æƒ³ï¼š**
- [ ] æ£€æŸ¥baselineæ˜¯å¦æ­£ç¡®ï¼ˆä¸è®ºæ–‡å¯¹æ¯”ï¼‰
- [ ] åˆ†æé”™è¯¯ç±»å‹ï¼ˆæ˜¯å“ªé‡Œå‡ºé—®é¢˜ï¼‰
- [ ] æ£€æŸ¥æ£€ç´¢è´¨é‡ï¼ˆRecall@kæ˜¯å¦è¶³å¤Ÿé«˜ï¼‰
- [ ] å°è¯•ä¸åŒpromptæ¨¡æ¿
- [ ] å¢åŠ è®­ç»ƒæ•°æ®æˆ–epoch

**å¦‚æœæ£€ç´¢å¤ªæ…¢ï¼š**
- [ ] ä½¿ç”¨ANNç´¢å¼•è€ŒéFlat
- [ ] å‡å°‘topk
- [ ] æ‰¹é‡æ£€ç´¢
- [ ] æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ

**å¦‚æœæ˜¾å­˜ä¸è¶³ï¼š**
- [ ] å‡å°‘batch_size
- [ ] å¼€å¯gradient checkpointing
- [ ] å¼€å¯offloadï¼ˆparam/grad/optimizerï¼‰
- [ ] ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆ3Bè€Œé7Bï¼‰
- [ ] å‡å°‘max_prompt_length

---

## ğŸŠ é¢„æœŸæˆæœ

å®Œæˆæœ¬é¡¹ç›®åï¼Œä½ å°†è·å¾—ï¼š

1. **æŠ€æœ¯èƒ½åŠ›**
   - æ·±å…¥ç†è§£RAGå’Œå¯¹è¯ç³»ç»Ÿ
   - æŒæ¡RLè®­ç»ƒLLMçš„å®è·µç»éªŒ
   - ç†Ÿæ‚‰å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒæµç¨‹

2. **é¡¹ç›®æˆæœ**
   - ä¸€ä¸ªå¯è¿è¡Œçš„å¯¹è¯å¼æ£€ç´¢é—®ç­”ç³»ç»Ÿ
   - å®Œæ•´çš„å®éªŒä»£ç å’Œæ–‡æ¡£
   - è¯¦ç»†çš„å®éªŒæŠ¥å‘Šå’Œåˆ†æ

3. **æ½œåœ¨åº”ç”¨**
   - å®¢æœå¯¹è¯ç³»ç»Ÿ
   - å­¦æœ¯æ–‡çŒ®æ£€ç´¢åŠ©æ‰‹
   - ä¸ªäººçŸ¥è¯†åº“é—®ç­”

4. **å­¦æœ¯ä»·å€¼**ï¼ˆå¦‚æœåšå¾—å¥½ï¼‰
   - å¯ä»¥å‘è¡¨workshopè®ºæ–‡
   - å¯ä»¥ä½œä¸ºæ¯•ä¸šè®¾è®¡
   - å¯ä»¥å¼€æºè´¡çŒ®ç¤¾åŒº

---

## ğŸ“… æ—¶é—´è§„åˆ’ç¤ºä¾‹ï¼ˆ6å‘¨å®Œæ•´å®æ–½ï¼‰

| å‘¨ | æ—¥æœŸ | ä¸»è¦ä»»åŠ¡ | æ—¶é—´æŠ•å…¥ | æ£€æŸ¥ç‚¹ |
|----|------|----------|----------|--------|
| 1 | Week 1 | æ•°æ®é›†æ¢ç´¢ + æ•°æ®å¤„ç†è„šæœ¬ | 15-20h | ç”Ÿæˆtrain.parquet |
| 2 | Week 2 | ç³»ç»Ÿé€‚é… + å°è§„æ¨¡è¯•è¿è¡Œ | 15-20h | è®­ç»ƒè¿è¡ŒæˆåŠŸ |
| 3 | Week 3 | Baselineå®Œæ•´è®­ç»ƒ | 10häººå·¥ + 2å¤©GPU | EM > 40% |
| 4 | Week 4 | è¿›é˜¶å®éªŒï¼ˆ3-5ç»„ï¼‰ | 10häººå·¥ + 3å¤©GPU | å¤šç»„ç»“æœ |
| 5 | Week 5 | æ·±å…¥åˆ†æ + ä¼˜åŒ–è¿­ä»£ | 20h | æ€§èƒ½æå‡ |
| 6 | Week 6 | æ–‡æ¡£æ’°å†™ + æ•´ç†ä»£ç  | 15h | å®Œæ•´äº¤ä»˜ |

**æ€»è®¡ï¼š** çº¦85-100å°æ—¶äººå·¥ + 5-6å¤©GPUæ—¶é—´

---

å¥½äº†ï¼Œè¿™å°±æ˜¯å®Œæ•´çš„QReCCå®æ–½è®¡åˆ’ï¼

**å»ºè®®ä½ ç°åœ¨åšçš„äº‹ï¼š**
1. â­ æ”¶è—è¿™ä¸ªæ–‡æ¡£
2. ğŸ“ æ ¹æ®è‡ªå·±çš„æ—¶é—´é€‰æ‹©æ¨è¿›ç­–ç•¥ï¼ˆå¿«é€Ÿ/å®Œæ•´/è®ºæ–‡çº§ï¼‰
3. âœ… ä»ç¬¬ä¸€ä¸ªæ£€æŸ¥æ¸…å•å¼€å§‹æ‰§è¡Œ
4. ğŸ’¬ æœ‰é—®é¢˜éšæ—¶é—®æˆ‘ï¼

ç¥ä½ é¡¹ç›®é¡ºåˆ©ï¼ğŸš€